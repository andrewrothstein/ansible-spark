---
spark_ver : '2.3.0'
spark_hadoop_ver : hadoop2.7
spark_mirror_url : https://archive.apache.org/dist/spark
spark_checksums:
  '2.2.0':
    # https://archive.apache.org/dist/spark/spark-2.2.0/spark-2.2.0-bin-hadoop2.7.tgz
    hadoop2.7: sha256:97fd2cc58e08975d9c4e4ffa8d7f8012c0ac2792bcd9945ce2a561cf937aebcc
  '2.2.1':
    # https://archive.apache.org/dist/spark/spark-2.2.1/spark-2.2.1-bin-hadoop2.7.tgz
    hadoop2.7: sha256:79fb8285546670923a66082324bf56e99a7201476a52dea908804ddfa04f16c8
  '2.3.0':
    # https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.6.tgz
    hadoop2.6: sha256:2e341ae3eb45eb46832e2a664b5660ae4c3517dd3c4b24340f3a2972dce26461
    # https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz
    hadoop2.7: sha256:5cfbc77d140454c895f2d8125c0a751465f53cbe12720da763b1785d25c63f05
  
spark_parent_dir: /usr/local
spark_timeout: 10

# SPARK_HOME and PATH envs would be updated with this installation. To set other Spark related env, use the dictionary below
#spark_envs:
#  SPARK_OPTS: --driver-java-options=-Xmx4096M
#  PYTHONPATH: $SPARK_HOME/python
